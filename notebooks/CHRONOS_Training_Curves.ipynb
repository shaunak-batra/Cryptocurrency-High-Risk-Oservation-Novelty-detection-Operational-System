{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# CHRONOS Training with Logging\n",
                "\n",
                "Train CHRONOS model and generate training curves.\n",
                "\n",
                "**Output:**\n",
                "- Training/validation loss curves\n",
                "- F1/Precision/Recall over epochs\n",
                "- Best model checkpoint"
            ],
            "metadata": {
                "id": "intro"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install torch torch-geometric pandas numpy scikit-learn matplotlib -q\n",
                "print('Dependencies installed!')"
            ],
            "metadata": {
                "id": "install"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import files\n",
                "print('Upload the 3 Elliptic CSV files:')\n",
                "uploaded = files.upload()"
            ],
            "metadata": {
                "id": "upload"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch_geometric.nn import GATConv\n",
                "from torch_geometric.data import Data\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.metrics import f1_score, precision_score, recall_score\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f'Device: {device}')"
            ],
            "metadata": {
                "id": "imports"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Load data\n",
                "print('Loading data...')\n",
                "features_df = pd.read_csv('elliptic_txs_features.csv', header=None)\n",
                "classes_df = pd.read_csv('elliptic_txs_classes.csv')\n",
                "edges_df = pd.read_csv('elliptic_txs_edgelist.csv')\n",
                "\n",
                "tx_ids = features_df[0].values\n",
                "timesteps = features_df[1].values\n",
                "X = features_df.iloc[:, 2:].values.astype(np.float32)\n",
                "\n",
                "id_to_idx = {tx_id: idx for idx, tx_id in enumerate(tx_ids)}\n",
                "\n",
                "y = np.full(len(tx_ids), -1)\n",
                "for _, row in classes_df.iterrows():\n",
                "    tx_id = row['txId']\n",
                "    if tx_id in id_to_idx:\n",
                "        idx = id_to_idx[tx_id]\n",
                "        label = str(row['class'])\n",
                "        if label == '1': y[idx] = 0\n",
                "        elif label == '2': y[idx] = 1\n",
                "\n",
                "edge_list = []\n",
                "for _, row in edges_df.iterrows():\n",
                "    src, dst = row['txId1'], row['txId2']\n",
                "    if src in id_to_idx and dst in id_to_idx:\n",
                "        edge_list.append([id_to_idx[src], id_to_idx[dst]])\n",
                "\n",
                "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
                "\n",
                "# Masks\n",
                "train_mask = torch.tensor((timesteps >= 1) & (timesteps <= 34) & (y >= 0), dtype=torch.bool)\n",
                "val_mask = torch.tensor((timesteps >= 35) & (timesteps <= 42) & (y >= 0), dtype=torch.bool)\n",
                "test_mask = torch.tensor((timesteps >= 43) & (timesteps <= 49) & (y >= 0), dtype=torch.bool)\n",
                "\n",
                "# Data object\n",
                "data = Data(\n",
                "    x=torch.tensor(X, dtype=torch.float32),\n",
                "    y=torch.tensor(y, dtype=torch.long),\n",
                "    edge_index=edge_index,\n",
                "    train_mask=train_mask,\n",
                "    val_mask=val_mask,\n",
                "    test_mask=test_mask\n",
                ").to(device)\n",
                "\n",
                "print(f'Nodes: {data.num_nodes}, Train: {train_mask.sum()}, Val: {val_mask.sum()}, Test: {test_mask.sum()}')"
            ],
            "metadata": {
                "id": "load_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Simple GNN Model\n",
                "class SimpleGNN(nn.Module):\n",
                "    def __init__(self, in_features, hidden_dim=64, num_heads=4):\n",
                "        super().__init__()\n",
                "        self.proj = nn.Linear(in_features, hidden_dim)\n",
                "        self.gat1 = GATConv(hidden_dim, hidden_dim, heads=num_heads, concat=False)\n",
                "        self.gat2 = GATConv(hidden_dim, hidden_dim, heads=num_heads, concat=False)\n",
                "        self.classifier = nn.Linear(hidden_dim, 2)\n",
                "    \n",
                "    def forward(self, x, edge_index):\n",
                "        h = F.relu(self.proj(x))\n",
                "        h = F.relu(self.gat1(h, edge_index))\n",
                "        h = F.dropout(h, p=0.3, training=self.training)\n",
                "        h = F.relu(self.gat2(h, edge_index))\n",
                "        return self.classifier(h)\n",
                "\n",
                "model = SimpleGNN(data.num_features).to(device)\n",
                "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')"
            ],
            "metadata": {
                "id": "model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Training setup\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
                "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 5.0]).to(device))  # Class imbalance\n",
                "\n",
                "# Logging\n",
                "history = {\n",
                "    'epoch': [], 'train_loss': [], 'val_loss': [],\n",
                "    'train_f1': [], 'val_f1': [],\n",
                "    'val_precision': [], 'val_recall': []\n",
                "}\n",
                "\n",
                "# Training loop\n",
                "num_epochs = 100\n",
                "best_val_f1 = 0\n",
                "\n",
                "for epoch in range(1, num_epochs + 1):\n",
                "    # Train\n",
                "    model.train()\n",
                "    optimizer.zero_grad()\n",
                "    out = model(data.x, data.edge_index)\n",
                "    train_loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
                "    train_loss.backward()\n",
                "    optimizer.step()\n",
                "    \n",
                "    # Eval\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        out = model(data.x, data.edge_index)\n",
                "        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
                "        \n",
                "        train_pred = out[data.train_mask].argmax(dim=1).cpu()\n",
                "        val_pred = out[data.val_mask].argmax(dim=1).cpu()\n",
                "        \n",
                "        train_f1 = f1_score(data.y[data.train_mask].cpu(), train_pred)\n",
                "        val_f1 = f1_score(data.y[data.val_mask].cpu(), val_pred)\n",
                "        val_prec = precision_score(data.y[data.val_mask].cpu(), val_pred)\n",
                "        val_rec = recall_score(data.y[data.val_mask].cpu(), val_pred)\n",
                "    \n",
                "    # Log\n",
                "    history['epoch'].append(epoch)\n",
                "    history['train_loss'].append(train_loss.item())\n",
                "    history['val_loss'].append(val_loss.item())\n",
                "    history['train_f1'].append(train_f1)\n",
                "    history['val_f1'].append(val_f1)\n",
                "    history['val_precision'].append(val_prec)\n",
                "    history['val_recall'].append(val_rec)\n",
                "    \n",
                "    if val_f1 > best_val_f1:\n",
                "        best_val_f1 = val_f1\n",
                "        torch.save(model.state_dict(), 'best_model_training.pt')\n",
                "    \n",
                "    if epoch % 10 == 0:\n",
                "        print(f'Epoch {epoch}: Train F1={train_f1:.4f}, Val F1={val_f1:.4f}')\n",
                "\n",
                "print(f'\\nBest Val F1: {best_val_f1:.4f}')"
            ],
            "metadata": {
                "id": "train"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Plot training curves\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot(history['epoch'], history['train_loss'], label='Train')\n",
                "axes[0].plot(history['epoch'], history['val_loss'], label='Val')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].set_title('Training Loss')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True)\n",
                "\n",
                "# F1\n",
                "axes[1].plot(history['epoch'], history['train_f1'], label='Train')\n",
                "axes[1].plot(history['epoch'], history['val_f1'], label='Val')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('F1 Score')\n",
                "axes[1].set_title('F1 Score')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True)\n",
                "\n",
                "# Precision/Recall\n",
                "axes[2].plot(history['epoch'], history['val_precision'], label='Precision')\n",
                "axes[2].plot(history['epoch'], history['val_recall'], label='Recall')\n",
                "axes[2].set_xlabel('Epoch')\n",
                "axes[2].set_ylabel('Score')\n",
                "axes[2].set_title('Precision & Recall')\n",
                "axes[2].legend()\n",
                "axes[2].grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print('Saved training_curves.png')"
            ],
            "metadata": {
                "id": "plot"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Save history\n",
                "history_df = pd.DataFrame(history)\n",
                "history_df.to_csv('training_history.csv', index=False)\n",
                "\n",
                "# Download\n",
                "files.download('training_curves.png')\n",
                "files.download('training_history.csv')\n",
                "files.download('best_model_training.pt')"
            ],
            "metadata": {
                "id": "save"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}