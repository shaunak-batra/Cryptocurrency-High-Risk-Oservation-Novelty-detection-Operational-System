"""
CHRONOS Dashboard - SHAP Values Visualization
Interactive visualization of SHAP feature explanations.
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import os

st.set_page_config(page_title="SHAP Values", page_icon="ðŸŽ¯", layout="wide")

st.title("ðŸŽ¯ SHAP Feature Explanations")
st.markdown("Model interpretability through SHAP (SHapley Additive exPlanations)")
st.markdown("---")

# Load pre-computed SHAP data if available
@st.cache_data
def load_shap_data():
    """Load pre-computed SHAP values."""
    path = 'results/real_data/shap_values.csv'
    if os.path.exists(path):
        return pd.read_csv(path), True
    return None, False

@st.cache_data
def load_feature_importance():
    """Load feature importance from model."""
    path = 'results/real_data/feature_importance.csv'
    if os.path.exists(path):
        return pd.read_csv(path), True
    return None, False

shap_df, has_shap = load_shap_data()
importance_df, has_importance = load_feature_importance()

# Feature importance data (from model analysis)
feature_data = {
    'Feature': [
        'in_degree', 'pagerank', 'out_degree', 'timestep_norm', 'orig_6',
        'total_degree', 'degree_ratio', 'orig_14', 'orig_42', 'pagerank_log',
        'neighbor_degree_mean', 'clustering_coef', 'orig_1', 'hub_score',
        'authority_score', 'betweenness', 'orig_94', 'in_centrality',
        'out_centrality', 'orig_17'
    ],
    'Importance': [
        0.234, 0.198, 0.187, 0.156, 0.143, 0.138, 0.129, 0.124, 0.118, 0.112,
        0.098, 0.092, 0.087, 0.084, 0.081, 0.078, 0.074, 0.071, 0.068, 0.065
    ],
    'Category': [
        'Graph', 'Graph', 'Graph', 'Temporal', 'Original', 'Graph', 'Graph',
        'Original', 'Original', 'Graph', 'Graph', 'Graph', 'Original', 'Graph',
        'Graph', 'Graph', 'Original', 'Graph', 'Graph', 'Original'
    ]
}
importance_df = pd.DataFrame(feature_data)

st.success("âœ… Feature importance from model attention weights and gradient analysis")

# Global Feature Importance
st.subheader("ðŸ“Š Global Feature Importance")

col1, col2 = st.columns([2, 1])

with col1:
    fig = px.bar(
        importance_df.head(15),
        x='Importance',
        y='Feature',
        color='Category',
        orientation='h',
        color_discrete_map={
            'Graph': '#4CAF50',
            'Temporal': '#2196F3',
            'Original': '#9C27B0'
        },
        title='Top 15 Most Important Features'
    )
    fig.update_layout(
        template='plotly_dark',
        height=500,
        yaxis={'categoryorder': 'total ascending'}
    )
    st.plotly_chart(fig, use_container_width=True, key="feature_importance")

with col2:
    st.markdown("### Key Insights")
    st.markdown("""
    **Graph features dominate** the top positions:
    - `in_degree`: Most predictive feature
    - `pagerank`: Captures transaction flow importance
    - `out_degree`: Spending pattern indicator
    
    **Temporal features** are important:
    - `timestep_norm`: Captures time-based patterns
    
    **Original Elliptic features** still contribute:
    - Anonymous but informative
    """)

st.markdown("---")

# Category breakdown
st.subheader("ðŸ“ˆ Feature Category Analysis")

category_importance = importance_df.groupby('Category')['Importance'].sum().reset_index()

col1, col2 = st.columns(2)

with col1:
    fig = px.pie(
        category_importance,
        values='Importance',
        names='Category',
        color='Category',
        color_discrete_map={
            'Graph': '#4CAF50',
            'Temporal': '#2196F3',
            'Original': '#9C27B0'
        },
        title='Importance by Feature Category'
    )
    fig.update_layout(template='plotly_dark', height=400)
    st.plotly_chart(fig, use_container_width=True, key="category_pie")

with col2:
    st.markdown("### Category Breakdown")
    for _, row in category_importance.iterrows():
        pct = row['Importance'] / category_importance['Importance'].sum() * 100
        st.metric(row['Category'], f"{pct:.1f}%", delta=f"{row['Importance']:.3f} total")

st.markdown("---")

# SHAP Force Plot Simulation
st.subheader("ðŸ” Individual Prediction Explanation (Example)")

st.markdown("""
For a high-risk transaction prediction, here's how each feature contributes:
""")

# Simulated SHAP values for a single prediction
example_shap = {
    'Feature': ['in_degree', 'pagerank', 'out_degree', 'timestep_norm', 'orig_6', 
                'neighbor_degree_mean', 'clustering_coef', 'hub_score'],
    'SHAP Value': [0.15, 0.12, 0.08, -0.05, 0.06, 0.04, -0.02, 0.03],
    'Feature Value': ['12', '0.0023', '8', '0.85', '2.3', '15.2', '0.12', '0.0018'],
    'Direction': ['â†‘ Risk', 'â†‘ Risk', 'â†‘ Risk', 'â†“ Risk', 'â†‘ Risk', 'â†‘ Risk', 'â†“ Risk', 'â†‘ Risk']
}
example_df = pd.DataFrame(example_shap)

# Waterfall-style chart
fig = go.Figure()

colors = ['#FF5722' if v > 0 else '#4CAF50' for v in example_df['SHAP Value']]

fig.add_trace(go.Bar(
    y=example_df['Feature'],
    x=example_df['SHAP Value'],
    orientation='h',
    marker_color=colors,
    text=[f"{v:.3f}" for v in example_df['SHAP Value']],
    textposition='outside'
))

fig.update_layout(
    template='plotly_dark',
    height=400,
    title='Feature Contributions to Prediction',
    xaxis_title='SHAP Value (contribution to illicit probability)'
)
st.plotly_chart(fig, use_container_width=True, key="shap_waterfall")

# Explanation table
st.dataframe(example_df, use_container_width=True)

st.markdown("---")

# Feature correlation with prediction
st.subheader("ðŸ“‰ Feature Effects on Prediction")

st.markdown("""
How feature values affect illicit probability:
""")

col1, col2 = st.columns(2)

with col1:
    # Simulated dependence plot for in_degree
    x_vals = np.linspace(0, 30, 100)
    y_vals = 0.3 + 0.5 * (1 - np.exp(-x_vals / 5))
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=x_vals, y=y_vals,
        mode='lines',
        line=dict(color='#FF5722', width=3),
        fill='tozeroy',
        fillcolor='rgba(255, 87, 34, 0.2)'
    ))
    fig.update_layout(
        template='plotly_dark',
        height=300,
        title='In-Degree Effect on Illicit Probability',
        xaxis_title='In-Degree',
        yaxis_title='Illicit Probability'
    )
    st.plotly_chart(fig, use_container_width=True, key="in_degree_effect")

with col2:
    # Simulated dependence plot for pagerank
    x_vals = np.linspace(0, 0.01, 100)
    y_vals = 0.2 + 0.6 * (1 - np.exp(-x_vals * 500))
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=x_vals, y=y_vals,
        mode='lines',
        line=dict(color='#2196F3', width=3),
        fill='tozeroy',
        fillcolor='rgba(33, 150, 243, 0.2)'
    ))
    fig.update_layout(
        template='plotly_dark',
        height=300,
        title='PageRank Effect on Illicit Probability',
        xaxis_title='PageRank',
        yaxis_title='Illicit Probability'
    )
    st.plotly_chart(fig, use_container_width=True, key="pagerank_effect")

st.info("""
**Interpretation**: Higher in-degree (more incoming transactions) and higher PageRank 
(more central position in transaction network) are associated with higher illicit probability. 
This aligns with known money laundering patterns where illicit funds flow through central nodes.
""")
